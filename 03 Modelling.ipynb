{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Prediction of Obesity Risk\n",
    "Run after following notebooks are run:\n",
    "1. **01 Data Cleaning**\n",
    "2. **02 EDA**\n",
    "\n",
    "## Development Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('train_clean.pkl')\n",
    "test = pd.read_pickle('test_clean.pkl')\n",
    "\n",
    "## separate in to features and response variable\n",
    "x_train = train.drop('NObeyesdad', axis=1)\n",
    "y_train = train['NObeyesdad']\n",
    "\n",
    "x_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  ['Sometimes', 'no', 'Frequently']\n",
      "Categories (4, object): ['no' < 'Sometimes' < 'Frequently' < 'Always']\n",
      "test:  ['Sometimes', 'no', 'Frequently', 'Always']\n",
      "Categories (4, object): ['no' < 'Sometimes' < 'Frequently' < 'Always']\n"
     ]
    }
   ],
   "source": [
    "## take note of 'CALC' - train has 3 levels, but test has 4\n",
    "print('train: ', x_train.CALC.unique())\n",
    "print('test: ', x_test.CALC.unique())\n",
    "\n",
    "CALC_levels = x_test.CALC.cat.categories.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender_Male',\n",
       " 'family_history_with_overweight_yes',\n",
       " 'FAVC_yes',\n",
       " 'CAEC_Frequently',\n",
       " 'CAEC_Sometimes',\n",
       " 'CAEC_no',\n",
       " 'SMOKE_yes',\n",
       " 'SCC_yes',\n",
       " 'MTRANS_Bike',\n",
       " 'MTRANS_Motorbike',\n",
       " 'MTRANS_Public_Transportation',\n",
       " 'MTRANS_Walking',\n",
       " 'CALC_Sometimes',\n",
       " 'CALC_Frequently',\n",
       " 'CALC_Always',\n",
       " 'Age',\n",
       " 'Height',\n",
       " 'Weight',\n",
       " 'FCVC',\n",
       " 'NCP',\n",
       " 'CH2O',\n",
       " 'FAF',\n",
       " 'TUE']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## list categorical columns, excluding CALC, that can be assigned automatically\n",
    "cols_onehot_auto = x_train.columns[x_train.dtypes=='category'].drop('CALC')\n",
    "\n",
    "## use ColumnTransformer so only categorical columns are affected\n",
    "ct = ColumnTransformer([('One_Hot_Cat', OneHotEncoder(drop='first'), cols_onehot_auto),\n",
    "                        ('One_Hot_Cat_Manual', OneHotEncoder(drop='first', categories=[CALC_levels]), ['CALC'])],\n",
    "                       remainder='passthrough', verbose_feature_names_out=False)\n",
    "x_train_onehot = pd.DataFrame(ct.fit_transform(x_train), columns=ct.get_feature_names_out())\n",
    "x_test_onehot = pd.DataFrame(ct.transform(x_test), columns=ct.get_feature_names_out())\n",
    "\n",
    "x_train_onehot.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Insufficient_Weight', 'Normal_Weight', 'Obesity_Type_I',\n",
       "       'Obesity_Type_II', 'Obesity_Type_III', 'Overweight_Level_I',\n",
       "       'Overweight_Level_II'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## label encode response variable\n",
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mlogloss-mean</th>\n",
       "      <th>train-mlogloss-std</th>\n",
       "      <th>test-mlogloss-mean</th>\n",
       "      <th>test-mlogloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.102056</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.280454</td>\n",
       "      <td>0.00725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-mlogloss-mean  train-mlogloss-std  test-mlogloss-mean  \\\n",
       "99             0.102056            0.002044            0.280454   \n",
       "\n",
       "    test-mlogloss-std  \n",
       "99            0.00725  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## convert data to DMatrix\n",
    "x_train_onehot_D = xgb.DMatrix(data=x_train_onehot, label=y_train_le)\n",
    "\n",
    "## cross-validation\n",
    "params = {'objective':'multi:softprob', 'num_class':7, 'max_depth':8, 'eta':0.1}\n",
    "xgb_tuning = xgb.cv(dtrain=x_train_onehot_D, params=params, num_boost_round=100, early_stopping_rounds=20, nfold=5, as_pandas=True, seed=123)\n",
    "\n",
    "## mean result\n",
    "xgb_tuning.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params = {'colsample_bytree': 0.5, 'eta': 0.1, 'max_depth': 8, 'n_estimators': 150, 'n_jobs': -1, 'num_class': 7, 'objective': 'multi:softprob', 'reg_alpha': 1}\n",
      "best_score = 0.9106368363627922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9095769 , 0.91058864, 0.90948067, 0.91063684, 0.90933605,\n",
       "       0.91058869, 0.90707166, 0.9073611 , 0.90678278, 0.90659034,\n",
       "       0.90721647, 0.90745755])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## hyperparameter tuning: n_estimators\n",
    "param_grid = {'n_estimators' : np.arange(100,250,50), 'max_depth':[8], 'eta':[0.1], 'colsample_bytree': [0.5, 1], 'reg_alpha':[0.5, 1],        # parameters to tune\n",
    "              'objective':['multi:softprob'], 'num_class':[7], 'n_jobs' : [-1]}                                                                 # fixed parameters\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=8)\n",
    "\n",
    "xgb_tuning = GridSearchCV(xgb.XGBClassifier(random_state=8), param_grid, scoring='accuracy', cv=kf)\n",
    "xgb_tuning.fit(x_train_onehot.values, y_train_le)\n",
    "\n",
    "## find best param with lowest log loss, and plot params against mse\n",
    "xgb_tuning_accr = xgb_tuning.cv_results_['mean_test_score']\n",
    "print('best_params =', xgb_tuning.best_params_)\n",
    "print('best_score =', xgb_tuning.best_score_)\n",
    "xgb_tuning_accr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instantiate xgb algorithm, using best tuned param\n",
    "xgbclass = xgb.XGBClassifier(n_estimators= 150, max_depth=8, eta=0.1, colsample_bytree=0.5, reg_alpha=1, objective='multi:softprob', num_class=7, random_state=8, n_jobs=-1)\n",
    "\n",
    "## fit model to training data\n",
    "xgbclass.fit(x_train_onehot.values, y_train_le); None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up submission format - i.e. Id & NObeyesdad\n",
    "id = np.arange(len(train), len(train)+len(test))\n",
    "submission = pd.DataFrame(data={'id':id, 'NObeyesdad':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## xgb prediction\n",
    "y_testpred_xgb = xgbclass.predict(x_test_onehot.values)\n",
    "y_testpred_xgb = le.inverse_transform(y_testpred_xgb)\n",
    "submission['NObeyesdad'] = y_testpred_xgb\n",
    "submission.to_csv('Submissions/test_pred_xgb_v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
